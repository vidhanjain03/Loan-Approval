{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data,test_size):\n",
    "    \n",
    "    if isinstance(test_size,float):\n",
    "        test_size = round(test_size*len(data))\n",
    "\n",
    "    indices = data.index.tolist()\n",
    "    test_indices = random.sample(population=indices,k=test_size) #Sample function operate on list\n",
    "\n",
    "    test_data = data.loc[test_indices]\n",
    "    train_data = data.drop(test_indices)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:,-1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    \n",
    "    label_column = data[:,-1]\n",
    "    unique_classes, count_unique_classes = np.unique(label_column, return_counts=True)\n",
    "    index = count_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    feature_types = []\n",
    "    n_unique_values_thrashold = 15\n",
    "    \n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        example_value = unique_values[0]\n",
    "        \n",
    "        if (isinstance(example_value,str)) or (len(unique_values) <= n_unique_values_thrashold):\n",
    "            feature_types.append(\"Catagorical\")\n",
    "        else:\n",
    "            feature_types.append(\"Continuous\")\n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data, random_subspace):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    n = np.size(data,axis=1)\n",
    "    column_indicies = list(range(n-1))\n",
    "    \n",
    "    if random_subspace <= len(column_indicies):\n",
    "        column_indicies = random.sample(population=column_indicies,k=random_subspace)\n",
    "    \n",
    "    for column_index in column_indicies:\n",
    "        unique_values = np.unique(data[:,column_index])\n",
    "        \n",
    "        potential_splits[column_index] = unique_values\n",
    "                \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    \n",
    "    label_column = data[:,-1]\n",
    "    _,counts = np.unique(label_column,return_counts=True)\n",
    "    probablities = counts/(np.sum(counts))\n",
    "    entropy = sum(probablities * (-np.log2(probablities)))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def calculate_overall_entropy(data_below,data_above):\n",
    "    \n",
    "    n_data_points = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below)/n_data_points\n",
    "    p_data_above = len(data_above)/n_data_points\n",
    "    overall_entropy = (p_data_below * calculate_entropy(data_below)) + (p_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "    overall_entropy = 999\n",
    "    \n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below,data_above = data_split(data,column_index,value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below,data_above)\n",
    "            \n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "                \n",
    "    return best_split_column,best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data,split_column,split_value):\n",
    "    \n",
    "    split_column_values = data[:,split_column]\n",
    "    \n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == 'Continuous':\n",
    "        data_below = data[split_column_values <= split_value]\n",
    "        data_above = data[split_column_values > split_value]\n",
    "    else:\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "    \n",
    "    return data_below,data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(tf,counter=0,min_samples=2,max_depth=5,random_subspace=None):\n",
    "    \n",
    "    #data preperation\n",
    "    if(counter == 0):\n",
    "        global COLUUMN_HEADER, FEATURE_TYPES\n",
    "        COLUUMN_HEADER = tf.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(tf)\n",
    "        data = tf.values\n",
    "    else:\n",
    "        data = tf\n",
    "        \n",
    "    #base_case\n",
    "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    #recursive_part\n",
    "    else:\n",
    "        counter += 1\n",
    "        \n",
    "        #helper functions\n",
    "        potential_splits = get_potential_splits(data, random_subspace)\n",
    "        best_split_column,best_split_value = determine_best_split(data,potential_splits)\n",
    "        data_below, data_above = data_split(data, best_split_column, best_split_value)\n",
    "        \n",
    "        #check for empty data\n",
    "        if len(data_below) == 0 or len(data_above) == 0:\n",
    "            classification = classify_data(data)\n",
    "            return classification\n",
    "        \n",
    "        #instate sub tree\n",
    "        feature_column = COLUUMN_HEADER[best_split_column]\n",
    "        type_of_column = FEATURE_TYPES[best_split_column]\n",
    "        if type_of_column == \"Continuous\":\n",
    "            question = \"{} <= {}\".format(feature_column,best_split_value)\n",
    "        else:\n",
    "            question = \"{} = {}\".format(feature_column,best_split_value)\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        #find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(data_below,counter,min_samples,max_depth,random_subspace)\n",
    "        no_answer = decision_tree_algorithm(data_above,counter,min_samples,max_depth,random_subspace)\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example,tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split()\n",
    "\n",
    "    #ask question\n",
    "    if example[feature_name] <= float(value):\n",
    "        answer = tree[question][0]\n",
    "    else:\n",
    "        answer = tree[question][1]\n",
    "\n",
    "    #base_Case\n",
    "    if not isinstance(answer,dict):\n",
    "        return answer\n",
    "    #rescursive_part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example,residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping(train_df, n_bootstrap):\n",
    "    bootstrap_indices = np.random.randint(0,len(train_df),n_bootstrap)\n",
    "    df_bootstrap = train_df.iloc[bootstrap_indices]\n",
    "\n",
    "    return df_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_algorithm(tf,n_trees,n_bootstrap,n_features, dt_max_depth):\n",
    "    forest = []\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "        df_bootstrap = bootstrapping(tf,n_bootstrap)\n",
    "        tree = decision_tree_algorithm(df_bootstrap,max_depth=dt_max_depth,random_subspace=n_features)\n",
    "        forest.append(tree)\n",
    "    \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_predictions(test,forest):\n",
    "    \n",
    "    df_predictions = {}\n",
    "    for i in range(len(forest)):\n",
    "        column_name = \"Tree_{}\".format(i)\n",
    "        predictions = []\n",
    "        for j in range(len(test)):\n",
    "            prediction = classify_example(test.iloc[j], tree=forest[i])\n",
    "            predictions.append(prediction)\n",
    "        df_predictions[column_name] = predictions\n",
    "    df_predictions = pd.DataFrame(df_predictions)\n",
    "    \n",
    "    random_forest_predictions = df_predictions.mode(axis=1)[0]\n",
    "    return random_forest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df,predictions):\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    df['correct_classification'] = predictions == df['Species']\n",
    "    accuracy = df.correct_classification.mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
